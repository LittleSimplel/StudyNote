# 1 幂等性

## 1.1 什么是幂等性

**接口幂等性就是用户对同一操作发起的一次请求和多次请求结果是一致的**，不会因为多次点击而产生了副作用，比如支付场景，用户购买了商品，支付扣款成功，但是返回结果的时候出现了网络异常，此时钱已经扣了，用户再次点击按钮，此时就会进行第二次扣款，返回结果成功，用户查询余额发现多扣钱了，流水记录也变成了两条。这就没有保证接口幂等性

## 1.2 不幂等操作

- 用户多次点击按钮
- 用户页面回退再次提交
- 微服务互相调用，由于网络问题，导致请求失败，feign触发重试机制
- mq消息重试

## 1.3 什么情况下需要幂等

**单表单库：**

1. select                          - 天然幂等
2. update                        
   - SET col1=1           - 幂等
   - SET col1=col+1    - 不幂等
3. delete                          - 天然幂等
4. insert                           - 不幂等

解决方案：

1. insert                            设置唯一的业务主键
2. update                          乐观锁

**分布式：**

上述方案不能解决方案分布式项目和多表多库情况下得幂等问题

## 1.4 幂等解决方案

### 1.4.1 token 机制

- 服务端提供了发送 `token` 的接口，我们在分析业务的时候，哪些业务是存在幂等性问题的，就必须在执行业务前，先获取 `token`，服务器会把 `token` 保存到 redis 中

- 然后调用业务接口请求时， 把 `token` 携带过去，一般放在请求头部

- 服务器判断 `token` 是否存在 `redis`，存在表示第一次请求，然后删除 `token`，继续执行业务

- 如果判断 `token` 不存在 `redis` 中，就表示重复操作，直接返回重复标记给 `client`，这样就保证了业务代码，不被重复执行

危险性：

**1、先删除 token 还是后删除 token：**

1. 先删除可能导致，业务确实没有执行，重试还得带上之前的 token, 由于防重设计导致，请求还是不能执行
2. 后删除可能导致，业务处理成功，但是服务闪断，出现超时，没有删除掉token，别人继续重试，导致业务被执行两次
3. **我们最后设计为先删除 token，如果业务调用失败，就重新获取 token 再次请求**

**2、Token 获取，比较 和删除 必须是原子性**

1. redis.get（token），token.equals、redis.del（token）,如果说这两个操作都不是原子，可能导致，在高并发下，都 get 同样的数据，判断都成功，继续业务并发执行
2. 可以在 redis 使用 lua 脚本完成这个操作

```java
String token = UUID.randomUUID().toString().replace("-", "");
		confirmVo.setOrderToken(token);
		stringRedisTemplate.opsForValue().set(OrderConstant.USER_ORDER_TOKEN_PREFIX + memberRsepVo.getId(), token, 10, TimeUnit.MINUTES);
// token返回给前端
return confirmVo;
```

```java
	    // 1. 验证令牌 [必须保证原子性] 返回 0 or 1
		// 0 令牌删除失败 1删除成功
		String script = "if redis.call('get',KEYS[1]) == ARGV[1] then return redis.call('del',KEYS[1]) else return 0 end";
		String orderToken = vo.getOrderToken();

		// 原子验证令牌 删除令牌
		Long result = stringRedisTemplate.execute(new DefaultRedisScript<>(script, Long.class), Arrays.asList(OrderConstant.USER_ORDER_TOKEN_PREFIX + memberRsepVo.getId()), orderToken);
		if(result == 0L){
			// 令牌验证失败
			submitVo.setCode(1);
		}else{
			// 令牌验证成功
        }
```

### 1.4.2 各种锁机制

##### 1、数据库悲观锁

select * from xxx where id = 1 for update;

for update 查询的时候锁定这条记录 别人需要等待

悲观锁使用的时候一般伴随事务一起使用，数据锁定时间可能会很长，需要根据实际情况选用，另外需要注意的是，id字段一定是主键或唯一索引，不然可能造成锁表的结果，处理起来会非常麻烦

##### 2、数据库的乐观锁

这种方法适合在更新的场景中

update t_goods set count = count - 1,version = version + 1 where good_id = 2 and version = 1

根据 version 版本，也就是在操作数据库存前先获取当前商品的 version 版本号，然后操作的时候带上 version 版本号，我们梳理下，我们第一次操作库存时，得

到 version 为 1，调用库存服务 version = 2，但返回给订单服务出现了问题，订单服务又一次调用了库存服务，当订单服务传的 version 还是 1，再执行上面的

 sql 语句 就不会执行，因为 version 已经变成 2 了，where 条件不成立，这样就保证了不管调用几次，只会真正处理一次，乐观锁主要使用于处理读多写少的问题

##### 3、业务层分布锁

如果多个机器可能在同一时间处理相同的数据，比如多台机器定时任务拿到了相同的数据，我们就可以加分布式锁，锁定此数据，处理完成后后释放锁，获取锁必须先判断这个数据是否被处理过。

### 1.4.3 redis set 防重

很多数据需要处理，只能被处理一次，比如我们可以计算数据的 MD5 将其放入 redis 的set,每次处理数据，先看这个 MD5 是否已经存在，存在就不处理

### 1.4.4 防重表

使用订单表 `orderNo` 做为去重表的唯一索引，把唯一索引插入去重表，再进行业务操作，且他们在同一个事务中，这样就保证了重复请求时，因为去重表有唯一约束，导致请求失败，避免了幂等性等问题，去重表和业务表应该在同一个库中，这样就保证了在同一个事务，即使业务操作失败，也会把去重表的数据回滚，这个很好的保证了数据的一致性

### 1.4.5 全局请求唯一id

调用接口时，生成一个唯一的id，redis 将数据保存到集合中（去重），存在即处理过，可以使用 nginx 设置每一个请求一个唯一id

proxy_set_header X-Request-Id $Request_id

## 1.5 幂等的不足

幂等是为了简化客户端逻辑处理，却增加了服务提供者的逻辑和成本，是否有必要，需要根据具体场景具体分析，因此除了业务上的特殊要求外，尽量不提供幂等的接口。

1. 增加了额外控制幂等的业务逻辑，复杂化了业务功能；
2. 把并行执行的功能改为串行执行，降低了执行效率

# 2. 分布式事务

## 2.1 为什么要有分布式事务

分布式系统经常出现的异常，机器宕机、网络异常、消息丢失、消息乱序、不可靠的TCP、存储数据丢失...，造成数据不一致。

分布式事务是在分布式环境下能保证数据一致性。

## 2.2 CAP 理论

#### 1、CAP 定理

CAP 原则又称 CAP 定理指的是在一个分布式系统中

- **一致性（Consistency）**

  - 在分布式系统中所有数据备份，在同一时刻是否是同样的值，（等同于所有节点访问同一份最新数据的副本）

- **可用性（Avaliability）**

  - 在集群中一部分节点故障后，集群整体是否还能响应客户端的读写请求，（对数据更新具备高可用性）

- **分区容错性（Partition tolerance）**

  - 分布式系统在遇到任何网络分区故障时，仍然能够对外提供满足一致性和可用性的服务，除非是整个网络环境都发生故障。

  分区容错性的理解：

  > **一个分布式系统里面，节点组成的网络本来应该是连通的。然而可能因为一些故障，使得有些节点之间不连通了，整个网络就分成了几块区域。数据就散布在了这些不连通的区域中。这就叫分区。**
  >
  > **当你一个数据项只在一个节点中保存，那么分区出现后，和这个节点不连通的部分就访问不到这个数据了。这时分区就是无法容忍的。**
  >
  > **提高分区容忍性的办法就是一个数据项复制到多个节点上，那么出现分区之后，这一数据项就可能分布到各个区里。容忍性就提高了。**
  >
  > **然而，要把数据复制到多个节点，就会带来一致性的问题，就是多个节点上面的数据可能是不一致的。要保证一致，每次写操作就都要等待全部节点写成功，而这等待又会带来可用性的问题**
  >
  > 总的来说就是，数据存在的节点越多，分区容忍性越高，但要复制更新的数据就越多，一致性就越难保证。为了保证一致性，更新所有节点数据所需要的时间就越长，可用性就会降低

CAP 的原则是，这三个要素最多只能满足两个点，**不可能三者兼顾**

## 2.3 面临的问题

对于大多数互联网应用的场景、主机众多、部署分散，而且集群规模越来越大，所以节点故障，网络故障是常态，而且要保证服务可用性达到99.999%，即保证P 和 A,舍弃C。

##  2.4 BASE 理论

是对CAP的延申，思想即是无法做到强一致性（CAP的一致性就是强一致性），但可以采用适当的弱一致性，即**最终一致性**

BASE 是指

- 基本可用（Basically Avaliable）
  - 基本可用是指分布式系统中在出现故障的时候，允许损失部分可用性（列入响应时间，功能上的可用性）允许损失部分可用性。需要注意的是基本可用不等价于系统不可用
  - 响应时间上的损失，正常情况下搜索引擎需要在0.5秒之内返回给用户相应的查询结果，但由于出现故障（比如系统部分机房断电断网故障），查询的结果响应时间增加到了1~2秒
  - 功能上的损失，购物网站双十一购物高峰，为了保证系统的稳定性，部分消费者会被引入到一个降级页面
- **软状态（Soft State）**
  - 软状态是指允许 系统存在中间状态，而该中间状态不会影响系统整体可用性。分布式存储中一般一份数据会有 多个副本，允许不同副本同步的延时就是软状态的体现。mysglreplication的异步复制也是一种体现。
- **最终一致性( Eventual Consistency)**
  - 最终致性是指系统中的所有数据副本经过一定时间后，最终能够达到一 致的状态。弱一致性和强一致性相反，最终-致性是弱一致性的一种特殊情况

## 2.5 强一致性、弱一致性、最终一致性

从客户端角度，多进程并发访问时，更新过的数据在不同进程如何获取的不同策略，决定了不同的一致性。对于关系型数据库，要求更新过的数据能被后续的访问都能看到，这是强一致性。如果能容忍后续的部分或者全部访问不到，则是弱一致性。如果经过一段时间后要求能访问到更新后的数据，则是最终一致性

## 2.6 分布式事务的几种方案

关于事务的一些概念

- 事务：事务是由一组操作构成的可靠的独立的工作单元，事务具备ACID的特性，即原子性、一致性、隔离性和持久性
- 本地事务：当事务由**资源管理器**本地管理时被称作本地事务。本地事务的优点就是支持严格的ACID特性，高效，可靠，状态可以只在资源管理器中维护，而且应用编程模型简单。但是本地事务不具备分布式事务的处理能力，隔离的最小单位受限于资源管理器。
- 全局事务：当事务由全局事务管理器进行全局管理时成为全局事务，事务管理器负责管理全局的事务状态和参与的资源，协同资源的一致提交回滚。
- TX协议：应用或者应用服务器与事务管理器的接口。
- XA协议：全局事务管理器与资源管理器的接口。XA是由X/Open组织提出的分布式事务规范。该规范主要定义了全局事务管理器和局部资源管理器之间的接口。主流的数据库产品都实现了XA接口。XA接口是一个双向的系统接口，在事务管理器以及多个资源管理器之间作为通信桥梁。之所以需要XA是因为在分布式系统中从理论上讲两台机器是无法达到一致性状态的，因此引入一个单点进行协调。由全局事务管理器管理和协调的事务可以跨越多个资源和进程。全局事务管理器一般使用XA二阶段协议与数据库进行交互。
- AP：应用程序，可以理解为使用DTP（Data Tools Platform）的程序
- RM：资源管理器，这里可以是一个DBMS或者消息服务器管理系统，应用程序通过资源管理器对资源进行控制，资源必须实现XA定义的接口。资源管理器负责控制和管理实际的资源。
- TM：事务管理器，负责协调和管理事务，提供给AP编程接口以及管理资源管理器。事务管理器控制着全局事务，管理事务的生命周期，并且协调资源
- 两阶段提交协议：XA用于在全局事务中协调多个资源的机制。TM和RM之间采取两阶段提交的方案来解决一致性问题。两节点提交需要一个协调者（TM）来掌控所有参与者（RM）节点的操作结果并且指引这些节点是否需要最终提交。两阶段提交的局限在于协议成本，准备阶段的持久成本，全局事务状态的持久成本，潜在故障点多带来的脆弱性，准备后，提交前的故障引发一系列隔离与恢复难题。
- 刚性事务:遵循ACID原则，强一致性。
- 柔性事务:遵循BASE理论，最终一致性;

### 1、2PC 模式（强一致性）

有一个事务管理器的概念，负责协调多个数据库的事务，两阶段指的是：准备阶段、提交阶段。准备阶段完成资源操作，提交阶段提交事务。准备阶段如果任何其中一个数据库回答不 ok，那么就回滚事务。提供强一致性保障，在事务执行过程中，所有的资源都是被锁定的，这种情况只适合执行时间确定的**短事务**。

![img](D:\study\github\StudyNote\开发\开发体系\解决方案\img\184629-20201210164410737-1804966761.png)

**问题：**

- 单点故障，如果在提交阶段节点故障，会导致数据不一致
- 全局锁，锁定时间长
- 性能差

### 2、柔性事务 - TCC 事务（最终一致性）

TCC模式可以解决2PC中资源锁定和阻塞问题，减少资源锁定时间。
TCC 的全称是：Try、Confirm、Cancel。

- Try 阶段：这个阶段说的是对各个服务的资源做检测和预留。
- Confirm 阶段：这个阶段说的是在各个服务中执行实际的操作。
- Cancel 阶段：如果任何一个服务的业务方法执行出错，那么这里就需要进行补偿，就是执行已经执行成功的业务逻辑的回滚操作。（把那些执行成功的回滚）。

<img src="D:\study\github\StudyNote\开发\开发体系\解决方案\img\184629-20201101095114875-787574024.png" alt="img" style="zoom:67%;" />

**优点:**

Try、Confirm、Cancel这三个阶段都是独立事务，互不影响，每一阶段都会提交本地事务并释放锁。如果事务执行失败，就执行补偿操作，不是回滚。这样就避免了资源长期锁定和阻塞。性能比较好。

**缺点**：

- TCC方案是严重依赖于你自己写代码来回滚和补偿了，会造成补偿代码巨大。数据库也要相应设计。需要些代码实现try、commit、cancel接口。
- cancel动作有可能失败。

### 3、柔性事务 - 最大努力通知型方案

按规律进行通知，**不保证数据定能通知成功， 但会提供可查询操作接口进行核对**。这种方案主要用在与第三方系统通讯时，比如:调用微信或支付宝支付后的支付结果通知。这种方案也是结合MQ进行实现，例如:通过MQ发送http请求，设置最大通知次数。达到通知次数后即不再通知。

使用范围：对业务最终一致性的时间敏感度低。跨企业的业务活动

案例:银行通知、商户通知等(各大交易业务平台间的商户通知:多次通知、查询校对、对账文件)，支付宝的支付成功异步回调

### 4、柔性事务 - 可靠信息 + 最终一致性方案（异步通知型）

基于mq的可靠性投递（业务接口幂等性设计）参见mq消息可靠性投递

### 业内解决框架

SpringCloud Alibaba-Seata