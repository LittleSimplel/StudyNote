### 大数据介绍

#### 为什么用大数据平台

- 数据存储的演进

  ![数据库.jpg](http://ww1.sinaimg.cn/large/0062TeRXgy1gdwkijxii3j312y0int9y.jpg)

- 据解决了什么问题
  - 数据存储     对比数据库
  - 数据计算   (数据库简单计算，复杂计算 应用代码) 
    - jvm内存 系统内存
    - 计算性能（多线程） cup
- 怎么解决的( 垂直和水平)
  - 数据存储 水平扩展
  - 数据计算 水平扩展
- 无法相互替代，根据具体业务场景选型

#### 大数据平台组件介绍

- hadoop(在分布式服务器集群上存储海量数据并运行分布式分析应用的开源框架)

  - 分布式存储 HDFS
  - 分布式计算 MapReduce
  - 任务调度 yarn

- hbase

  列式存储

- flume

  数据采集工具

- kafka

  消息队列

- hive

  数仓 sql语句分析   离线分析

- spark

  数据分析 实时分析

#### 架构流程

![大数据组件流程.jpg](http://ww1.sinaimg.cn/large/0062TeRXgy1gdwswqghe4j30xu0iawh6.jpg)

#### 项目案列 

- 离线分析

  - v1.0  应用程序通过定时分析mysql数据，得到一张mysql中间表，拿中间表取数据实现可视化
  - v2.0  数据清洗 
    1. 通过datax把数据转移到hive中，作为原表
    2. 构建定时任务组，在定时任务组中构建定时任务，定时任务中有条件查询语句，根据条件查询语句查询出来的数据存储到hive中，hive要提前建立对应字段的数据清洗表，
    3. 清洗完成之后再通过datax把数据转移到mysql中，通过mysql 查询数据 
    4. 建立api接口数据配置，通过api接口获取数据

- 实时分析(pvuv)

  ![puvu流程图.png](http://ww1.sinaimg.cn/large/0062TeRXgy1gdvmpy27i2j30yu05qwez.jpg)

1. 用户请求
2. 请求到达网关，开一线程处理请求数据（获取请求信息：用户信息，操作信息），将处理数据发送到Kafka
3. 在SparkStreaming中消费数据，连接Hbase，在Hbase存储每个用户的**第一次访问时间和最后一次访问时间**，读取Hbase中每个用户的最后一次访问时间，通过对比最后一次访问时间和当前访问时间，可得到该用户在本小时，当前天是否为第一次访问。第一次访问设置uv=1,不然则uv=0，pv都是=1，通过map转换格式(key,value),key为固定值，value为访问类对象（包含uv，pv属性）。再通过reduceByKey 合并 key，key一样的将访问类对象中的uv，pv值求和，再将该用户pvuv数据存储到Hbase
4. 定时将Hbase的pvuv数据存到mysql
5. 数据显示

### 大数据服务

#### Hdfs

- 工作机制  

  - 概述

    1. HDFS集群分为两大角色:NameNode、DataNode
    2. NameNode负责客户端请求的响应，元数据的管理(查询、修改)
    3. DataNode负责管理用户的文件数据块(数据块的读/写操作)
    4. 文件会按照固定的大小(blocksize)切成若干块后分布式存储在若干台datanode上

  - 读数据

    客户端要向HDFS写数据，首先要跟namenode通信以确认可以写文件并获得接收文件block的datanode，然后客户端按顺序将文件逐个block传递给相应datanode(client 直连datanode)

    ![读取流程.png](http://ww1.sinaimg.cn/large/0062TeRXgy1ge1b6iwq8rj30x90e3q4h.jpg)

  - 写数据

    客户端要向HDFS写数据，首先要跟namenode通信以确认可以写文件并获得接收文件block的datanode，然后客户端按顺序将文件逐个block传递给相应datanode(client 直连datanode)

- 采坑 

  1. 生产环境 datanode开端口。

#### MapReduce

- 工作机制  
  - 概述
    - MapReduce将复杂的，运行大规模集群上的并行计算过程高度地抽象两个函数：Map和Reduce
    - MapReduce采用“分而治之”策略，将一个分布式文件系统中的大规模数据集，分成许多独立的分片。这些分片可以被多个Map任务并行处理。

- 流程

  ![mR流程.jpg](http://ww1.sinaimg.cn/large/0062TeRXgy1ge18sa2dqkj30zu0by418.jpg)

#### Hive

- 工作机制  

  数仓，对文件关系映射成一张表，hive 基于hdfs存储，基于MapReduce计算，提供类sql的分析查询语句

  跟换元数据库

  连接模式

- 优化 

  - 本地模式

    小于 128M 4个map 开启本地模式 比集群模式效率更高

  - 小文件合并

    ```
    set mapred.max.split.size=100000000; 
    set mapred.min.split.size.per.node=100000000; 
    set mapred.min.split.size.per.rack=100000000;
    ```

    前面三个参数确定合并文件块的大小，大于文件块大小128m的，按照128m来分隔，小于128m,大于100m的，按照100m来分隔，把那些小于100m的（包括小文件和分隔大文件剩下的）进行合并。

  - 数据倾斜（jion，null，分组维度小）

    ```
    set hive.map.aggr=true
    ```

  - 表连接优化：

    将大表放后头Hive假定查询中最后的一个表是大表。它会将其它表缓存起来，然后扫描最后那个表。因此通常需要将小表放前面。

  - order by & sort by 

    order by : 对查询结果进行全局排序消耗时间长,需要set hive.mapred.mode=nostrict

    sort by : 局部排序，并非全局有序，提高效率。

#### SPARK

- spark-RDD 算子 **分布式数据集**

  为用户屏蔽了底层对数据的复杂抽象和处理，为用户提供了一组方便的数据转换与求值方法

  **Trasformation 转换操作**

  - map
  - sortBy
  - reduceByKey
  - filter 过滤

  ### Action 动作

  - collect 收集
  - count 计数
  - reduce 聚合
  - countBykey 根据可以计数
  - take(n) 取出多少个元素
  - first 取第一个
  - takeOrdered(n) 排序取出多少个元素 正序
  - top(n) 倒序取出多少个元素

- demo演示

  - 单词统计

#### Hbase

- 服务架构

  ![hbase架构.jpg](http://ww1.sinaimg.cn/large/0062TeRXgy1gdvxogjfntj30qb0e2q59.jpg)

- 表结构

  ![hbase变结构.jpg](http://ww1.sinaimg.cn/large/0062TeRXgy1gdvy20mxaij30q10fw74k.jpg)

- 优化 （Region 分隔）

  Hbase中的表会被划分为n个Region，然后存放在多个RegionServer中，每个Region有StartKey和EndKey，表示这个Region维护的RowKey范围，而第一个Region没有StartKey，最后一个Region没有EndKey。需要读写数据时，RowKey会落在某个范围内，就会定位到目标的Region以及所在的RegionServer。
          默认情况下，创建表的时候只有一个Region，当表的数据增长，数据大小大于一定的阈值，HBase就会找到一个MidKey将Region一分为二，这个过程被称为Region-Split，而Split是有时间和资源开销的。

  ![hbaseRegion分裂.png](http://ww1.sinaimg.cn/large/0062TeRXgy1ge1bk673tfj30qk0ec0tw.jpg)

  - 分区键设计

    001，002，003，004

  - rowkey设计

    key.hash()%4  = 0，1，2，3   

    

### 搭建 

搭建文档已搭建好，几个注意的点。

- 端口问题
- 防火墙问题
- 开启主机名访问

### 总结

