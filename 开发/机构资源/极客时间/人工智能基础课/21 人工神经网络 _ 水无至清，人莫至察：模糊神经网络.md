<audio title="21 人工神经网络 _ 水无至清，人莫至察：模糊神经网络" src="https://static001.geekbang.org/resource/audio/dc/9b/dc91747273a8bf8735bb4ed0c0a05f9b.mp3" controls="controls"></audio> 
<p>模糊神经网络是一类特殊的神经网络，它是神经网络和模糊逻辑结合形成的混合智能系统，通过将模糊系统的类人推理方式与神经网络的学习和连接结构相融合来协同这两种技术。简单来说，<strong>模糊神经网络（fuzzy neural network）就是将常规的神经网络赋予模糊输入信号和模糊权值，其作用在于利用神经网络结构来实现模糊逻辑推理</strong>。</p>
<p>在生活中，我们在臧否人物时很少给出非黑即白的二元评价。这是因为每个人在生活中都扮演着复杂的多重角色，不是好人就是坏人的评判方式显然有失客观。这就是模糊理论在生活中最直接的体现。正如美国加州大学伯克利分校的洛特菲·扎戴所说：“当系统的复杂性增加时，我们使它精确化的能力将减小。直到达到一个阈值，一旦超越这个阈值，复杂性和精确性将相互排斥。”</p>
<p>1965年，正是这位洛特菲·扎戴提出了与模糊数学相关的一系列理论，并由此衍生出模糊系统的概念。1988年，供职于日本松下电气的高木秀幸和小林功提出了将神经网络与模糊逻辑结合的想法，这标志着神经模糊系统（Neuro-fuzzy system）的诞生。神经模糊系统的基础是<strong>模糊集合</strong>和一组“如果......那么......”形式的<strong>模糊规则</strong>，利用神经网络的非线性和学习机制获得类人的推理能力。1993年，意大利帕多瓦大学的乔万尼·波尔托兰提出了将多层前馈神经网络模糊化的思路，这就是这里所讨论的模糊神经网络。</p>
<p>需要说明的是，模糊神经网络和神经模糊系统是不同的。神经模糊系统的输入和输出都是确定对象。因此在神经模糊系统中，必备的结构是模糊化层和去模糊化层。模糊化层用于将输入的确定对象模糊化，去模糊化层则用于将输出的模糊对象转化为确定对象。相比之下，模糊神经网络的输入和输出都是模糊对象，完成的也是模糊推理的功能。</p>
<p>在介绍模糊神经网络之前，有必要对一些基本概念加以解释。模糊理论中最基本的概念是<strong>模糊集合</strong>。在不模糊的集合里，每个元素和集合之间的隶属关系是明确的，也就是要么属于集合，要么不属于集合，两者之间泾渭分明。可<strong>在模糊集合中，元素和集合之间的关系不是非此即彼的明确定性关系，而是用一个叫做隶属度的函数定量表示</strong>。在现实中评判某个人物的时候，通常会说他“七分功三分过”或是“三分功七分过”，这里的三七开就可以看成是隶属函数。</p>
<!-- [[[read_end]]] -->
<p><strong>模糊集合是对“对象和集合之间关系”的描述，模糊数描述的则是对象本身</strong>。“人到中年”是很多人愿意用来自嘲的一句话，可中年到底是个什么范围呢？利用排除法可以轻松确定25岁算不上中年，55岁也算不上中年，可要是对中年给出一个明确的正向定义就困难了。因而如果把“中年”看作一个数的话，它就是个模糊数。模糊数在数学上的严格定义是根据模糊集合推导出来的，是个归一化的模糊集合，但通俗地说，<strong>模糊数就是只有取值范围而没有精确数值的数</strong>。</p>
<p>模糊数可以用来构造模糊数据，对模糊数据进行运算时，依赖的规则叫做<strong>扩展原理</strong>。对两个确定的数做运算，得到的结果肯定还是一个确定的数。可一旦模糊数参与到运算中来，得到的结果也将变成一个模糊数。扩展原理及其引申得到的模糊算术，定义的就是运算给模糊数的模糊程度带来的变化，这当然也是一个通俗的说法。在模糊算术中，传统的加减乘和内积等运算都被改造成对模糊集合的运算。</p>
<p>有了这些概念，就可以进一步解释模糊神经网络。模糊神经网络的拓扑与架构和传统的多层前馈神经网络相同，但其输入信号和权重系数都是模糊集合，因而其输出信号同样是模糊集合。而在网络内部，处理输入信号和权重系数的则是模糊数学，隐藏神经元表示的就是隶属函数和模糊规则。模糊化的处理必然会影响神经网络的特性，因而学习算法的设计和通用逼近特性的保持就成为模糊神经网络要解决的核心问题。</p>
<p><strong>构成模糊神经网络的基本单元是模糊化的神经元</strong>。模糊神经元的输入信号和权重系数都是模糊数，传递函数也需要对模糊集合上的加权结果进行处理。模糊神经元的组合形成模糊神经网络。模糊神经网络的训练方式同传统的神经网络类似，即定义一个误差函数并使其最小化。但由于模糊数不能进行微积分的计算，因此不能直接对模糊的权重系数使用反向传播，需要在处理误差时需要针对模糊数的特性提出新的方法。两种常用的方法是<strong>基于水平集的方法</strong>和<strong>基于遗传算法的方法</strong>。</p>
<p>基于水平集的方法采用的是直接推导的方式，通过确定模糊集合的水平集对模糊数中的元素加以筛选。假如一个模糊数中包含三个元素x、y和z，其参数分别是0.3、0.6和0.7，那么当截断点等于0.5时，这个模糊数的0.5水平集就会把参数为0.3的元素x过滤掉，只保留参数大于0.5的y和z。在神经网络的训练中，训练算法的作用就是通过计算偏导数和应用反向传播算法，优化每个水平集的截断点，从而确定模糊权值。</p>
<p>水平集方法的致命缺陷在于缺乏理论依据，这严重限制了它的应用。一个不加任何限制的模糊数肯定不能用有限个参数来描述，因而要基于水平集方法来设计通用的模糊神经网络学习算法是不可能的。当模糊数被限制为三角形或者梯形时，算法可以得到一定的简化。</p>
<p>在模糊神经网络的训练中，如果保持学习率参数不变，误差函数就难以快速收敛。即使收敛也可能陷入局部最小值上，在不同的学习率参数下得到不同的局部最小值。为了处理这个问题，模糊神经网络引入了一种叫做“<strong>共轭梯度（conjugate gradient）”的机制</strong>，使训练过程能够找到全局最优解。而要确定最优的学习率，就要借助<strong>遗传算法</strong>（genetic algorithm）。</p>
<p>共轭梯度方法比较复杂，在这里不做展开。相比基于水平集的方法，基于遗传算法的方法是摸着石头过河，通过迭代逐步找到误差函数的最小值，从而确定权重系数。但它并没有解决水平集方法的本质问题，适用范围仍然被局限在三角形和梯形这类特殊的模糊数上，纯属换汤不换药的做法。</p>
<p>除了学习算法之外，<strong>逼近性能也是模糊神经网络设计中的核心问题</strong>。传统神经网络可以通过引入少量隐藏层实现对任意问题的逼近，但模糊神经网络能不能达到这个要求尚需证明。受学习算法的限制，对逼近性能的考察也只能针对特定类型的模糊神经网络进行。研究结果表明，当输入和权值都被限定为实数时，四层的前馈网络就足以逼近任意形式的模糊取值函数。这意味着模糊神经网络和传统神经网络的性能是相同的，因为抛去输入层和输出层之外，四层网络就只剩两个隐藏层了。</p>
<p><strong>模糊神经网络是一种混合智能系统，能够同时处理语言信息和数据信息，因而是研究非线性复杂系统的有效工具，也是软计算的核心研究内容之一，在模式识别、系统分析和信号处理等领域都有成功应用的实例</strong>。但相对于打了翻身仗的传统神经网络，摆在模糊神经网络面前的依然是雄关如铁的境地。</p>
<p>今天我和你分享了模糊神经网络的基本概念，其要点如下：</p>
<ul>
<li>模糊神经网络是神经网络和模糊逻辑结合形成的混合智能系统；</li>
<li>模糊神经网络的输入信号、权重系数和输出信号全都是模糊集合；</li>
<li>模糊神经网络的主要学习算法包括基于水平集的方法和基于遗传算法的方法；</li>
<li>模糊神经网络具有和传统神经网络类似的通用逼近特性。</li>
</ul>
<p>模糊理论代表了一种思维方式，它更接近于人类的思考习惯。那么融合了定性和定量的模糊理论会给用于规则推演的人工智能带来什么样的启发呢？</p>
<p>欢迎发表你的观点。</p>
<p><img src="https://static001.geekbang.org/resource/image/5d/e1/5d8c880ee0e5dd330df08e9db32558e1.jpg" alt=""></p>
<p></p>
