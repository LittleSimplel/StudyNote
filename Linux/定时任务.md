### 定时启动spark任务

判断spark任务是否正在运行，没有运行的话启动任务

1. 添加定时执行命令`vi /etc/crontab` 

   ```shell
   * * * * * root sh /usr/local/jar/autoStart.sh   # 没分钟执行一次 autoStart.sh 脚本
   ```

2. 启动spark任务时 使出 pid `echo $! > ./pid.txt`

   ```shell
   nohup /opt/hd/spark-2.3.3-bin-hadoop2.7/bin/spark-submit \
   --master local[8] \
   --class com.zyd.xtabd.service.spark.task.TraAnalyse \
   /usr/local/jar/wordcount.jar > /usr/local/jar/plog.out & echo $! > ./pid.txt
   ```

3. 编写脚本autoStart.sh

   ```shell
   #!/bin/bash
   echo "staring..." >> /usr/local/jar/echo.log
   PID=`cat /usr/local/jar/pid.txt`
   PIDS=`ps -ef |grep $PID|grep -v grep | awk '{print $2}'`
   if [ "$PIDS" != "" ]; then
   echo `date -d 'yesterday' +'%Y/%m/%d %H:%M:%S'`  >> /usr/local/jar/echo.log
   echo "running"  >> /usr/local/jar/echo.log
   else
   sh /usr/local/jar/spark_pvuv.sh
   fi
   ```

注意：autoStart.sh里的文件路径用 **绝对路径**



