### 大数据介绍

1. 为什么用大数据平台

   - 数据存储的演进

     ![数据库演进.png](http://ww1.sinaimg.cn/large/0062TeRXgy1gdvgw5fp8kj30yw0f0my6.jpg)

   - 据解决了什么问题(不讲概念)
     - 数据存储     对比数据库
     - 数据计算   (数据库简单计算，复杂计算 代码) 
       - jvm内存 系统内存
       - 计算性能（多线程） cup
   - 怎么解决的( 垂直 和水平)
     - 数据存储 水平扩展
     - 数据计算 水平扩展
   - 无法相互替代，根据具体业务场景选型

2. 大数据平台组件介绍

   - hadoop(在分布式服务器集群上存储海量数据并运行分布式分析应用的开源框架)

     - 分布式存储 HDFS

       图

     - 分布式计算 MapReduce

       图

     - 任务调度

   - hbse

     列式存储

   - flume

     采集工具

   - kafka

     消息队列

   - hive

     数仓

   - spark

3. 项目流程

   ![大数据架构图.png](http://ww1.sinaimg.cn/large/0062TeRXgy1gdvly4myssj30zm0j5tbq.jpg)

4. 项目案列 

   - 离线分析

     - 1.0  应用程序通过定时分析mysql数据，得到一张mysql中间表，拿中间表取数据实现可视化
     - 2.0  数据清洗 
       1. 通过datax把数据转移到hive中，作为原表
       2. 构建定时任务组，在定时任务组中构建定时任务，定时任务中有条件查询语句，根据条件查询语句查询出来的数据存储到hive中，hive要提前建立对应字段的数据清洗表，
       3. 清洗完成之后再通过datax把数据转移到mysql中，通过mysql 查询数据 
       4. 建立api接口数据配置，通过api接口获取数据

   - 实时分析(pvuv)

     ![puvu流程图.png](http://ww1.sinaimg.cn/large/0062TeRXgy1gdvmpy27i2j30yu05qwez.jpg)

   1. 用户请求
   2. 请求到达网关，开一线程处理请求数据（获取请求信息：用户信息，操作信息），将处理数据发送到Kafka
   3. 在SparkStreaming中消费数据，连接Hbase，在Hbase存储每个用户的**第一次访问时间和最后一次访问时间**，读取Hbase中每个用户的最后一次访问时间，通过对比最后一次访问时间和当前访问时间，可得到该用户在本小时，当前天是否为第一次访问。第一次访问设置uv=1,不然则uv=0，pv都是=1，通过map转换格式(key,value),key为固定值，value为访问类对象（包含uv，pv属性）。再通过reduceByKey 合并 key，key一样的将访问类对象中的uv，pv值求和，再将该用户pvuv数据存储到Hbase
   4. 定时将Hbase的pvuv数据存到mysql
   5. 数据显示

### 大数据服务

#### Hdfs

- 工作机制  

- 采坑 
- 优化 

#### MapReduce

- 工作机制  

- 采坑 
- 优化 

#### Hive

- 工作机制  

- 采坑 
- 优化 
  - 本地模式
  - 小文件合并
  - 数据倾斜（jion引起）

#### SPARK

- 工作机制  

- 采坑 
- 优化 

#### Hbase

- 工作机制  

- 采坑 
- 优化 

### 搭建 

搭建文档已搭建好，就不讲了，几个注意的点。

- 端口问题
- 防火墙问题
- 开启主机名访问